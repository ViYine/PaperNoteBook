{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 频率学派：\n",
    "- 频率学派认为概率是随机事件发生频率的极限值;\n",
    "- 频率学派执行参数估计时，视参数为确定取值，视数据为随机变量；\n",
    "- 频率学派主要使用最大似然估计法，让数据在给定参数下的似然概率最大化；\n",
    "- 频率学派对应机器学习中的统计学习，以经验风险最小化作为模型选择的准则。\n",
    "\n",
    "\n",
    "![频率学派](./ML/频率学派.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯学派\n",
    "\n",
    "- 贝叶斯学派认为概率是事件的可信程度或主体对事件的信任程度；\n",
    "- 贝叶斯学派执行参数估计时，视参数为随机变量，视数据为确定取值；\n",
    "- 贝叶斯学派主要使用最大后验概率法，让参数在先验信息和给定数据下的后验概率最大化；\n",
    "- 贝叶斯学派对应机器学习中的概率图模型，可以在模型预测和选择中提供更加完整的信息。\n",
    "\n",
    "![贝叶斯学派](./ML/贝叶斯学派.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习解决问题的特点：\n",
    "\n",
    "- 机器学习适用于解决蕴含潜在规律的问题；\n",
    "- 纯算数问题无需使用机器学习；\n",
    "- 机器学习需要大量数据来发现潜在规律；\n",
    "- 从输入空间、输出空间、数据标签、学习策略等角度可以对机器学习进行分类。\n",
    "\n",
    "![机器学习问题](./ML/机器学习问题.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算学习理论\n",
    "\n",
    "- Hoeffding 不等式描述了训练误差和泛化误差之间的近似关系；\n",
    "- PAC 学习理论的核心在于学习出来的模型会以较大概率接近于最优模型；\n",
    "- 假设空间的VC维是对无限假设空间复杂度的度量，体现了复杂性和性能的折中；\n",
    "- Rademacher复杂度是结合了先验信息的对函数空间复杂度的度量。\n",
    "\n",
    "![计算学习理论](./ML/计算学习理论.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习模型分类\n",
    "\n",
    "- 不同的学习思路对应假设空间中不同的建模方式与学习方法；\n",
    "- 参数模型和非参数模型的区别体现的是全局普适性和局部适用性的区别；\n",
    "- 数据模型和算法模型的区别体现的是可解释性和精确性的区别；\n",
    "- 生成模型和判别模型的区别体现的是联合分布和条件分布的区别。\n",
    "\n",
    "![模型分类](./ML/模型分类.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型设计准则\n",
    "\n",
    "- 无免费午餐定理说明模型的选取要以问题的特点为根据；\n",
    "- 奥卡姆剃刀说明在性能相同的情况下，应该选取更加简单的模型；\n",
    "- 过于简单的模型会导致欠拟合，过于复杂的模型会导致过拟合；\n",
    "- 从误差分解的角度看，欠拟合模型的偏差较大，过拟合模型的方差较大。\n",
    "\n",
    "![模型设计准则](./ML/模型设计准则.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型验证\n",
    "\n",
    "- 模型验证的作用是选择最佳模型并确定其性能；\n",
    "- 对数据的重采样可以直接实现对样本外误差，也就是泛化误差的估计；\n",
    "- k折交叉验证是无放回的重采样方法；\n",
    "- 自助采样是有放回的重采样方法。\n",
    "\n",
    "在机器学习中，参数（parameter）和超参数（hyperparameter）是两个不同的概念。模型的参数是对模型的内部描述，超参数则是对模型的外部描述。对于多项式模型${f(x) = \\sum_{i=0}^{N} a_ix^i}$来说，所有的${a_i}$都是需要拟合的参数，而多项式的最高次数${N}$则是超参数。模型的验证实际上就是通过调整模型超参数来控制模型复杂度，从而找到一组预测能力最强的模型参数\n",
    "\n",
    "![模型验证](./ML/模型验证.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
